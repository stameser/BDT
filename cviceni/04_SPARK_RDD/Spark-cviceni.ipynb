{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Užitecne funkce Pythonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delka stringu je: 18\n",
      "String obsahuje slova: ['to', 'be', 'Or', 'NOT', 'to', 'be']\n",
      "String obsahuje unikatni slova: {'be', 'Or', 'NOT', 'to'}\n",
      "String prevedeny na mala pismena:  to be or not to be\n",
      "Delka pole (pocet slov) je: 6\n",
      "Prvni prvek v poli je: to\n",
      "Posledni prvek v poli je: be\n"
     ]
    }
   ],
   "source": [
    "my_string = \"to be Or NOT to be\"\n",
    "my_list = my_string.split()\n",
    "print 'Delka stringu je:', len(my_string)\n",
    "print 'String obsahuje slova:', my_string.split()\n",
    "print 'String obsahuje unikatni slova:', set(my_string.split())\n",
    "print 'String prevedeny na mala pismena: ', my_string.lower()\n",
    "print 'Delka pole (pocet slov) je:', len(my_list)\n",
    "print 'Prvni prvek v poli je:', my_list[0]\n",
    "print 'Posledni prvek v poli je:', my_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spustit interaktivni shell Spark-pythonu\n",
    "\n",
    "`pyspark --master yarn --num-executors 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priklad z prednasky: word count (nebo Hello hadoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(verse):    \n",
    "    return verse.split(' ')\n",
    "\n",
    "lines = sc.textFile(\"/user/pascepet/data/bible.txt\")\n",
    "words = lines.flatMap(split_string)\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
    "counts.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukol c. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani\n",
    "\n",
    "Upravte priklad z prednasky o nasledujici vylepseni (v libovolnem poradi):\n",
    "\n",
    "1. Vyberte RDD, ktere je vhodne si pro dalsi vypocty kesovat, a nakesujte ho.\n",
    "1. Na konci seradte slova podle cetnosti sestupne (Hint: sortBy nebo sortByKey).\n",
    "1. Pocitejte slovo jako stejne bez ohledu na velikost pismen.\n",
    "1. Neberte v uvahu zacatek radku (nazev biblicke knihy a kod kapitola:vers -- je oddelen od textu tabulatorem).\n",
    "1. Odstrante z textu vsechny nealfanumericke znaky (napr. '.', ':', '-', -- nebo aspon nektere z nich)\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/data/bible.txt` na HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. kesovani:** napr.  \n",
    "`words.cache()` nebo `words = lines.flatMap(lambda line: line.split(\" \")).cache()`\n",
    "\n",
    "**2. serazeni slov podle cetnosti sestupne:**  \n",
    "`counts_sorted = counts.sortBy(lambda x: x[1], ascending=False)`\n",
    "\n",
    "**3. slova stejna bez ohledu na velikost pismen -- napr. prevodem slov na mala pismena:**  \n",
    "`words = words.map(lambda word: word.lower())`\n",
    "\n",
    "**4. oddeleni identifikace radku:**  \n",
    "`lines = lines.map(lambda line: line.split(\"\\t\")[1])`\n",
    "\n",
    "**5. odstraneni nealfanumerickych znaku:**  \n",
    "* vyhozeni urciteho nealfanum. znaku:  \n",
    "`words = words.map(lambda word: word.replace('.', '')`\n",
    "* vyhozeni vsech nealfanum. znaku:  \n",
    "`import re`  \n",
    "`words = words.map(lambda word: re.sub(r'\\W+', '', word))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukol c. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani \n",
    "\n",
    "a) Spocitejte pocet slov v kazdem versi (1 vers = 1 radek) a najdete verse s nejvetsim a nejmensim poctem slov.  \n",
    "b) Provedte stejny vypocet jako v bode a), ale pocitejte jen unikatni slova v kazdem versi.\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/bible.txt` na HDFS\n",
    "\n",
    "### Ocekavany vystup\n",
    "\n",
    "| verse_id | pocet_slov |\n",
    "|:---------|:-----------|\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod obsahuje reseni pro a) i b) zaroven\n",
    "# nacteni RDD\n",
    "lines = sc.textFile(\"/user/pascepet/data/bible.txt\") \n",
    "\n",
    "# rozdeleni radku na id a text, nakesujeme pro zrychleni opakovaneho behu\n",
    "lines2 = lines.map(lambda line: line.split(\"\\t\"))\n",
    "\n",
    "# vytvorime dvojici (id radku, list se slovy), nakesujeme pro zrychleni opakovaneho behu\n",
    "lines3 = lines2.map(lambda line: (line[0], line[1].split(\" \")))\n",
    "# bylo by mozne slova ocistit jako v ukolu c. 1, tj. prevest na mala pismena, vyhodit nealfanum. znaky apod.\n",
    "\n",
    "# spocteme slova a unikatni slova\n",
    "counts = lines3.map(lambda line: (line[0], len(line[1]))).cache()\n",
    "counts_uniq = lines3.map(lambda line: (line[0], len(set(line[1])))).cache()\n",
    "\n",
    "# setrideni radku podle poctu slov a dotaz na prvni prvek\n",
    "counts_sorted_asc = counts.sortBy(lambda x: x[1], True)\n",
    "counts_sorted_desc = counts.sortBy(lambda x: x[1], False)\n",
    "counts_sorted_asc.take(1)\n",
    "counts_sorted_desc.take(1)\n",
    "counts_uniq_sorted_asc = counts_uniq.sortBy(lambda x: x[1], True)\n",
    "counts_uniq_sorted_desc = counts_uniq.sortBy(lambda x: x[1], False)\n",
    "counts_uniq_sorted_asc.take(1)\n",
    "counts_uniq_sorted_desc.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukol c. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani\n",
    "\n",
    "a) Zjistete, ktery stat ma nejvyssi prumernou teplotu z mereni jen za mesice 6--8. Teplotu uvedte ve stupnich Celsia.  \n",
    "b) Pro kazdy mesic vypiste stat, ktery ma nejvyssi prumernou teplotu z mereni za tento mesic.\n",
    "\n",
    "### Data\n",
    "\n",
    "1. Na lokalnim filesystemu (tj. ne na HDFS) je vychozi soubor `/home/pascepet/fel_bigdata/data/teplota-usa.zip`. Tento soubor si zkopírujte do svého pracovního adresáře na lokálním filesystemu a rozbalte si ho tam.\n",
    "1. Po rozbaleni dostanete dva soubory CSV. Spojte si je do souboru `teplota.csv`.\n",
    "1. Soubor `teplota.csv` zkopirujte na HDFS do sveho pracovniho adresare.\n",
    "\n",
    "### Vstupni data\n",
    "\n",
    "CSV soubor ma jako oddelovac znak ','. Take obsahuje hlavicky s nazvy sloupcu, ktere je potreba pri zpracovani odstranit.    \n",
    "Teplota je uvedena v 10 * stupne Fahrenheita. Nektere radky neobsahuji zadnou namerenou teplotu (prazdny retezec).\n",
    "\n",
    "**Sloupce:** id_stanice, mesic, den, hodina, teplota, flag, latitude, longitude, vyska, stat, nazev\n",
    "\n",
    "\n",
    "### Ocekavany vystup\n",
    "\n",
    "V zadani a)\n",
    "\n",
    "| stat | prum_teplota | \n",
    "|:-----|:-------------|\n",
    "\n",
    "\n",
    "V zadani b)\n",
    "\n",
    "| mesic | stat | prum_teplota | \n",
    "|:------|:-----|:-------------|\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# nacteni RDD, odfiltrovani nezadoucich radku\n",
    "# !!! zde je treba dosadit cestu do vlastniho user adresare na HDFS\n",
    "lines = sc.textFile(\"/user/pascepet/data/teplota.csv\")\n",
    "lines2 = lines.filter(lambda line: not(re.match(r'stanice', line)))\n",
    "\n",
    "# prevod radku na strukturu ((mesic, stat), teplota)\n",
    "recs = lines2.map(lambda line: line.split(\",\"))\n",
    "# vyhozeni prazdnych udaju o teplote\n",
    "recs = recs.filter(lambda rec: rec[4]!='')\n",
    "# konverze z Fahrenheita na Celsia\n",
    "recs = recs.map(lambda rec: ((int(rec[1]), rec[9]), (float(rec[4])/10-32)*5/9))\n",
    "# nakesovani\n",
    "recs = recs.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# uloha a) stat s nejvetsi prumernou teplotou za mesice 6-8\n",
    "# vyhodit udaje za jine mesice\n",
    "recs1 = recs.filter(lambda rec: rec[0][0] in range(6,9))\n",
    "# ponecha jen nazev statu (mesic nas uz nezajima), k tomu pripravi dvojice pro agregaci\n",
    "recs1 = recs1.map(lambda rec: (rec[0][1], (1, rec[1])))\n",
    "result1 = recs1.reduceByKey(lambda s,t: (s[0]+t[0], s[1]+t[1]))  # agregace po statech - pocet a soucet \n",
    "result1 = result1.map(lambda res: (res[0], res[1][1]/res[1][0])) # prumer = soucet/pocet\n",
    "result1 = result1.sortBy(lambda res: res[1], False)\n",
    "result1.take(1)\n",
    "\n",
    "# uloha b) za kazdy mesic stat s nejvetsi prumernou teplotou\n",
    "# spocita se agregace za kazdou dvojici (mesic, stat)\n",
    "recs2 = recs.map(lambda rec: (rec[0], (1, rec[1])))\n",
    "result2 = recs2.reduceByKey(lambda s,t: (s[0]+t[0], s[1]+t[1]))\n",
    "result2 = result2.map(lambda res: (res[0], res[1][1]/res[1][0])) # nyni mame za kazdou dvojici (mesic, stat) prumernou teplotu\n",
    "result2 = result2.map(lambda res: (res[0][0], (res[0][1], res[1]))) # dame mesic jako klic a mezi staty budeme hledat maximum \n",
    "result3 = result2.reduceByKey(lambda s,t: (t if t[1]>s[1] else s))\n",
    "result3 = result3.sortBy(lambda res: res[0], True)\n",
    "result3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonusovy ukol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani\n",
    "\n",
    "V ukolu 1 vyradte ze zpracovani tzv. stop-slova.\n",
    "\n",
    "Hint: Pouzijte [Spark broadcast](https://spark.apache.org/docs/latest/rdd-programming-guide.html#broadcast-variables)\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/data/bible.txt` na HDFS    \n",
    "`/user/pascepet/data/stopwords.txt` na HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nacist stop slova do mnoziny muzete pomoci prikazu\n",
    "with open('/user/pascepet/data/stopwords.txt') as stopwords_file:\n",
    "    stopwords = set([x.replace('\\n', '') for x in stopwords_file.readlines()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pripravuje se :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
