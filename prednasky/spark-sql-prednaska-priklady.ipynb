{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### vypocet statu s nejvyssi prumernou teplotou v lete pomoci tradicniho Spark RDD\n",
    "# spusteni Sparku: pyspark --num-executors 2 --executor-memory 1500M --master yarn\n",
    "\n",
    "###  pomocne funkce\n",
    "# transformace dat z typu list na strukturu (stat, (teplota, 1))\n",
    "def uprav_radek(rlist):\n",
    "    stat = rlist[9]\n",
    "    tepl = (int(rlist[4])/10.0 - 32)*5/9\n",
    "    return (stat, (tepl, 1))\n",
    "\n",
    "# agregace paru (teplota, 1) na (soucet, pocet)\n",
    "def soucty(a, b):\n",
    "    soucetA = a[0]\n",
    "    soucetB = b[0]\n",
    "    pocetA = a[1]\n",
    "    pocetB = b[1]\n",
    "    return (soucetA + soucetB, pocetA + pocetB)\n",
    "\n",
    "# cteni teplot ze souboru\n",
    "teploty_raw = sc.textFile('/user/pascepet/data/teplota')\n",
    "\n",
    "# radek se prevede na typ list\n",
    "teploty1 = teploty_raw.map(lambda r: r.split(',')) \n",
    "\n",
    "# ponechaji se jen prvky RDD (radky) s mesicem 6-8 a neprazdnym udajem o teplote\n",
    "teploty2 = teploty1.filter(lambda rlist: (rlist[1] in set('678')) & (rlist[4] != ''))\n",
    "\n",
    "# z prvku RDD typu list se vytahnout jen potrebna data\n",
    "teploty3 = teploty2.map(uprav_radek)\n",
    "\n",
    "# agregace po statech\n",
    "teploty_staty = teploty3.reduceByKey(soucty)\n",
    "\n",
    "# vypocet prumeru pro stat, tj. transformace (stat, (soucet, pocet)) -> (stat, prumer)\n",
    "teploty_staty2 = teploty_staty.map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    "\n",
    "# serazeni\n",
    "teploty_staty3 = teploty_staty2.sortBy(lambda y: y[1], ascending=False)\n",
    "\n",
    "# vypise poradi statu\n",
    "teploty_staty3.take(1)\n",
    "teploty_staty3.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tri zpusoby nacteni dat jako DataFrame -------------------------------\n",
    "### 1. nacteni primo z CSV\n",
    "# u starsiho Sparku (1.6) je treba spustit Spark s externi knihovnou na cteni CSV\n",
    "# pyspark --num-executors 2 --executor-memory 1500M --packages com.databricks:spark-csv_2.10:1.5.0 --master yarn\n",
    "teploty_DF1 = sqlContext.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/user/pascepet/data/teplota\")\n",
    "\n",
    "\n",
    "### 2. nacteni z Hive (existuje-li tabulka)\n",
    "teploty_DF2 = sqlContext.sql('select * from fel_bigdata.teplota')\n",
    "\n",
    "### 3. prevod z existujiciho RDD\n",
    "from pyspark.sql import Row\n",
    "import re\n",
    "\n",
    "def uprav_radek_df_row(r):\n",
    "    rlist = r.split(',')\n",
    "    return Row(stanice=rlist[0], mesic=int(rlist[1]), den=int(rlist[2]), hodina=int(rlist[3]), \\\n",
    "        teplota=None if rlist[4]=='' else float(rlist[4]), flag=rlist[5], latitude=float(rlist[6]), \\\n",
    "        longitude=float(rlist[7]), vyska=float(rlist[8]), stat=rlist[9], nazev=rlist[10])\n",
    "\n",
    "# nacte RDD ze souboru\n",
    "teploty_raw = sc.textFile('/user/pascepet/data/teplota')\n",
    "teploty_prep = teploty_raw.filter(lambda line: not(re.match(r'stanice', line))) \\\n",
    "    .map(uprav_radek_df_row)\n",
    "teploty_DF3 = sqlContext.createDataFrame(teploty_prep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### prace s DataFrame: vypocet statu s nejvyssi teplotou pomoci Spark SQL -----\n",
    "### 1. registrace DataFrame jako docasne tabulky\n",
    "teploty_DF1.registerTempTable(\"tpDF\")\n",
    "\n",
    "# agregace pomoci SQL dotazu\n",
    "teploty_DF1_prum = sqlContext.sql(\"\"\"select stat, avg((teplota/10.0-32)*5/9) as tepl_prum from tpDF\n",
    "where mesic in (6,7,8)\n",
    "group by stat order by tepl_prum desc\"\"\")\n",
    "teploty_DF1_prum.show(10)\n",
    "\n",
    "\n",
    "### 2. pomoci pseudo-SQL operaci\n",
    "# ponechani jen neprazdnych dat za letni mesice\n",
    "teploty_DF_upr = teploty_DF1.filter((teploty_DF1['mesic']>=6) & (teploty_DF1['mesic']<=8)) \\\n",
    "    .select('stat','teplota').dropna()\n",
    "# pracujeme s originalnimi daty -> prepocet teploty na stupne Celsia\n",
    "teploty_DF_upr = teploty_DF_upr.withColumn('teplota', (teploty_DF_upr['teplota']/10.0 - 32) * 5/9)\n",
    "# agregace - prumery podle statu\n",
    "teploty_statyDF = teploty_DF_upr.groupBy('stat').avg('teplota') \\\n",
    "    .toDF('stat', 'tepl_prum')\n",
    "# serazeni podle prumerne teploty\n",
    "teploty_statyDF = teploty_statyDF.orderBy(teploty_statyDF['tepl_prum'].desc())\n",
    "# vypise poradi prvnich deseti statu\n",
    "teploty_statyDF.show(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
